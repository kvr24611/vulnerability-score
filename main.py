import pandas as pd
import requests
from bs4 import BeautifulSoup

 

# Function to scrape CVE data from cvedetails.com

def scrape_cve_details(cve_id):

    url = f"https://www.cvedetails.com/cve/{cve_id}/"

    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}

    response = requests.get(url, headers=headers)

    print(response)

    if response.status_code == 200:

        soup = BeautifulSoup(response.text, 'html.parser')


        div_element_score = soup.select_one('div.bg-white.rounded.p-1.border.table-responsive div.cvssbox')

        score, severity = None, None

        # Check if the div element exists
        if div_element_score:
        # Extract and print the text from the div element
            score = div_element_score.text
        print(score)


        div_element_severity_list = soup.find_all('td', class_='ps-2')

        if div_element_severity_list:
            severity = div_element_severity_list[1].text.strip()
        print(severity)



        return score, severity

    else:
        print(response)
        return None, None





     

# Read the input CSV file

input_file = 'input.csv'  # Replace with your input CSV file

df = pd.read_csv(input_file)

 

# Create lists to store the scraped data

cve_scores = []

cve_severities = []

 

# Iterate through each row in the input CSV and scrape data

for cve_id in df['CVE ID']:

    score, severity = scrape_cve_details(cve_id)

    cve_scores.append(score)

    cve_severities.append(severity)

 

# Add the scraped data to the DataFrame

df['CVE Score'] = cve_scores

df['CVE Severity'] = cve_severities

 

# Write the updated DataFrame to the output CSV file

output_file = 'output.csv'  # Replace with your output CSV file

df.to_csv(output_file, index=False)

 

print(f"Scraped data for {len(df)} CVE IDs and saved to {output_file}")